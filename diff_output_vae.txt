diff --git a/vae/main.py b/vae/main.py
index d69833f..5b860e6 100644
--- a/vae/main.py
+++ b/vae/main.py
@@ -6,7 +6,7 @@ from torch import nn, optim
 from torch.nn import functional as F
 from torchvision import datasets, transforms
 from torchvision.utils import save_image
-
+import intel_extension_for_pytorch as ipex
 
 parser = argparse.ArgumentParser(description='VAE MNIST Example')
 parser.add_argument('--batch-size', type=int, default=128, metavar='N',
@@ -16,25 +16,40 @@ parser.add_argument('--epochs', type=int, default=10, metavar='N',
 parser.add_argument('--no-cuda', action='store_true', default=False,
                     help='disables CUDA training')
 parser.add_argument('--no-mps', action='store_true', default=False,
-                        help='disables macOS GPU training')
+                    help='disables macOS GPU training')
+parser.add_argument('--use-xpu', action='store_true', default=False,
+                    help='use Intel XPU if available')
 parser.add_argument('--seed', type=int, default=1, metavar='S',
                     help='random seed (default: 1)')
 parser.add_argument('--log-interval', type=int, default=10, metavar='N',
                     help='how many batches to wait before logging training status')
 args = parser.parse_args()
-args.cuda = not args.no_cuda and torch.cuda.is_available()
-use_mps = not args.no_mps and torch.backends.mps.is_available()
 
 torch.manual_seed(args.seed)
 
-if args.cuda:
+# Device selection logic
+if args.use_xpu:
+    if hasattr(torch, 'xpu'):
+        if torch.xpu.is_available():
+            device = torch.device("xpu")
+            print("Using Intel XPU")
+        else:
+            print("Intel XPU not available, falling back to CPU")
+            device = torch.device("cpu")
+    else:
+        print("torch.xpu attribute not found, falling back to CPU")
+        device = torch.device("cpu")
+elif not args.no_cuda and torch.cuda.is_available():
     device = torch.device("cuda")
-elif use_mps:
+    print("Using CUDA")
+elif not args.no_mps and torch.backends.mps.is_available():
     device = torch.device("mps")
+    print("Using MPS")
 else:
     device = torch.device("cpu")
+    print("Using CPU")
 
-kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}
+kwargs = {'num_workers': 1, 'pin_memory': True} if not args.no_cuda and torch.cuda.is_available() else {}
 train_loader = torch.utils.data.DataLoader(
     datasets.MNIST('../data', train=True, download=True,
                    transform=transforms.ToTensor()),
@@ -43,7 +58,6 @@ test_loader = torch.utils.data.DataLoader(
     datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),
     batch_size=args.batch_size, shuffle=False, **kwargs)
 
-
 class VAE(nn.Module):
     def __init__(self):
         super(VAE, self).__init__()
@@ -59,9 +73,9 @@ class VAE(nn.Module):
         return self.fc21(h1), self.fc22(h1)
 
     def reparameterize(self, mu, logvar):
-        std = torch.exp(0.5*logvar)
+        std = torch.exp(0.5 * logvar)
         eps = torch.randn_like(std)
-        return mu + eps*std
+        return mu + eps * std
 
     def decode(self, z):
         h3 = F.relu(self.fc3(z))
@@ -72,10 +86,9 @@ class VAE(nn.Module):
         z = self.reparameterize(mu, logvar)
         return self.decode(z), mu, logvar
 
-
 model = VAE().to(device)
 optimizer = optim.Adam(model.parameters(), lr=1e-3)
-
+model, optimizer = ipex.optimize(model, optimizer=optimizer)  # Optimize model for Intel GPU
 
 # Reconstruction + KL divergence losses summed over all elements and batch
 def loss_function(recon_x, x, mu, logvar):
@@ -89,7 +102,6 @@ def loss_function(recon_x, x, mu, logvar):
 
     return BCE + KLD
 
-
 def train(epoch):
     model.train()
     train_loss = 0
@@ -110,7 +122,6 @@ def train(epoch):
     print('====> Epoch: {} Average loss: {:.4f}'.format(
           epoch, train_loss / len(train_loader.dataset)))
 
-
 def test(epoch):
     model.eval()
     test_loss = 0
@@ -138,3 +149,4 @@ if __name__ == "__main__":
             sample = model.decode(sample).cpu()
             save_image(sample.view(64, 1, 28, 28),
                        'results/sample_' + str(epoch) + '.png')
+
