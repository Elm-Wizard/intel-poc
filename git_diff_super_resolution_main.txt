diff --git a/super_resolution/main.py b/super_resolution/main.py
index 8c55195..0645832 100644
--- a/super_resolution/main.py
+++ b/super_resolution/main.py
@@ -8,6 +8,7 @@ import torch.optim as optim
 from torch.utils.data import DataLoader
 from model import Net
 from data import get_training_set, get_test_set
+import intel_extension_for_pytorch as ipex
 
 # Training settings
 parser = argparse.ArgumentParser(description='PyTorch Super Res Example')
@@ -17,27 +18,17 @@ parser.add_argument('--testBatchSize', type=int, default=10, help='testing batch
 parser.add_argument('--nEpochs', type=int, default=2, help='number of epochs to train for')
 parser.add_argument('--lr', type=float, default=0.01, help='Learning Rate. Default=0.01')
 parser.add_argument('--cuda', action='store_true', help='use cuda?')
-parser.add_argument('--mps', action='store_true', default=False, help='enables macOS GPU training')
+parser.add_argument('--ipex', action='store_true', help='use Intel PyTorch Extension')
 parser.add_argument('--threads', type=int, default=4, help='number of threads for data loader to use')
 parser.add_argument('--seed', type=int, default=123, help='random seed to use. Default=123')
 opt = parser.parse_args()
 
 print(opt)
 
-if opt.cuda and not torch.cuda.is_available():
-    raise Exception("No GPU found, please run without --cuda")
-if not opt.mps and torch.backends.mps.is_available():
-    raise Exception("Found mps device, please run with --mps to enable macOS GPU")
-
 torch.manual_seed(opt.seed)
-use_mps = opt.mps and torch.backends.mps.is_available()
-
+device = torch.device("cpu")  # Default to CPU, IPEX will enable GPU if available
 if opt.cuda:
     device = torch.device("cuda")
-elif use_mps:
-    device = torch.device("mps")
-else:
-    device = torch.device("cpu")
 
 print('===> Loading datasets')
 train_set = get_training_set(opt.upscale_factor)
@@ -46,11 +37,12 @@ training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, ba
 testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)
 
 print('===> Building model')
-model = Net(upscale_factor=opt.upscale_factor).to(device)
+model = Net(opt.upscale_factor).to(device)
 criterion = nn.MSELoss()
-
 optimizer = optim.Adam(model.parameters(), lr=opt.lr)
 
+if opt.ipex:
+    model, optimizer = ipex.optimize(model, optimizer=optimizer, dtype=torch.float32)  # Correctly include optimizer in the call
 
 def train(epoch):
     epoch_loss = 0
@@ -67,7 +59,6 @@ def train(epoch):
 
     print("===> Epoch {} Complete: Avg. Loss: {:.4f}".format(epoch, epoch_loss / len(training_data_loader)))
 
-
 def test():
     avg_psnr = 0
     with torch.no_grad():
@@ -80,7 +71,6 @@ def test():
             avg_psnr += psnr
     print("===> Avg. PSNR: {:.4f} dB".format(avg_psnr / len(testing_data_loader)))
 
-
 def checkpoint(epoch):
     model_out_path = "model_epoch_{}.pth".format(epoch)
     torch.save(model, model_out_path)
@@ -90,3 +80,4 @@ for epoch in range(1, opt.nEpochs + 1):
     train(epoch)
     test()
     checkpoint(epoch)
+
